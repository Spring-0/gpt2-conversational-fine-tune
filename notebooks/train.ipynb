{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "initial_id",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1733701600295,
     "user_tz": 300,
     "elapsed": 28593,
     "user": {
      "displayName": "Takis Panel",
      "userId": "10823998020771479779"
     }
    },
    "outputId": "ebb6b768-46b9-48dc-ddd7-09965cae362d"
   },
   "source": [
    "# Install dependencies (restart environment after installation)\n",
    "%pip install transformers\n",
    "%pip install matplotlib\n",
    "%pip install torch --index-url https://download.pytorch.org/whl/cu124\n",
    "%pip install accelerate\n",
    "%pip install pandas\n",
    "%pip install datasets\n",
    "%pip install numpy\n",
    "%pip install evaluate"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "d3512e968e3f9005",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1733703316450,
     "user_tz": 300,
     "elapsed": 16618,
     "user": {
      "displayName": "Takis Panel",
      "userId": "10823998020771479779"
     }
    },
    "ExecuteTime": {
     "end_time": "2024-12-09T19:32:25.666835Z",
     "start_time": "2024-12-09T19:32:19.881154Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import dependencies\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, TrainingArguments, Trainer\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset"
   ],
   "id": "d3512e968e3f9005",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "47bc275a1cc78b79",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1733703326623,
     "user_tz": 300,
     "elapsed": 184,
     "user": {
      "displayName": "Takis Panel",
      "userId": "10823998020771479779"
     }
    },
    "outputId": "fb1f484a-5856-45eb-f58d-35d4055f7e42",
    "ExecuteTime": {
     "end_time": "2024-12-09T19:38:52.813793Z",
     "start_time": "2024-12-09T19:38:52.810485Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# check for cuda gpu\n",
    "print(f\"[!] GPU Available: {torch.cuda.is_available()}\")"
   ],
   "id": "47bc275a1cc78b79",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] GPU Available: True\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e1c20748c9ca56be",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1733632881761,
     "user_tz": 300,
     "elapsed": 931,
     "user": {
      "displayName": "Karim Hamdan",
      "userId": "03463045303566388047"
     }
    },
    "outputId": "2c98a621-e9a2-4c3b-a9b1-8965bb4c39d5",
    "ExecuteTime": {
     "end_time": "2024-12-09T19:38:57.973832Z",
     "start_time": "2024-12-09T19:38:57.969965Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load gpt-2 model and tokenizer\n",
    "def load_model_and_tokenizer(local_path=\"./model\", model_name=\"gpt2\"):\n",
    "    if os.path.exists(local_path):\n",
    "        print(\"[+] loading model from local directory.\")\n",
    "        model = GPT2LMHeadModel.from_pretrained(local_path).to(\"cuda\")\n",
    "        tokenizer = GPT2Tokenizer.from_pretrained(local_path)\n",
    "    else:\n",
    "        print(\"[+] loading model from Hugging-Face hub\")\n",
    "        model = GPT2LMHeadModel.from_pretrained(model_name).to(\"cuda\")\n",
    "        tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "        \n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    return model, tokenizer"
   ],
   "id": "e1c20748c9ca56be",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "id": "9de753d60f743c3",
    "ExecuteTime": {
     "end_time": "2024-12-09T19:38:59.678491Z",
     "start_time": "2024-12-09T19:38:59.673541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Pre-process \"All-seasons.csv\" (south park dialog dataset)\n",
    "def preprocess_south_park_dialog_data(tokenizer, file_path=\"./data/All-seasons.csv\"):\n",
    "    dialog_data = []\n",
    "    \n",
    "    df = pd.read_csv(file_path, encoding=\"utf-8\")\n",
    "    lines = df[\"Line\"].dropna().values\n",
    "    \n",
    "    # Structure training data format\n",
    "    for i in range(0, len(lines) - 1, 2):\n",
    "        user = lines[i]\n",
    "        bot = lines[i+1]\n",
    "        dialog_data.append(f\"<USER>: {user} {tokenizer.eos_token}\\n<BOT>: {bot}{tokenizer.eos_token}\\n\")\n",
    "        \n",
    "    # Visualize data - printing the last 2 elements\n",
    "    print(\"\\n[+] Visualizing pre-processed south park dataset.\")\n",
    "    print(dialog_data[:2])\n",
    "    \n",
    "    return dialog_data"
   ],
   "id": "9de753d60f743c3",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "id": "60c5c3cfaf792526",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1733703626994,
     "user_tz": 300,
     "elapsed": 191,
     "user": {
      "displayName": "Takis Panel",
      "userId": "10823998020771479779"
     }
    },
    "ExecuteTime": {
     "end_time": "2024-12-09T19:39:01.454941Z",
     "start_time": "2024-12-09T19:39:01.451447Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Tokenize dialog data\n",
    "def tokenize_data(data, tokenizer, max_length=158):\n",
    "    return tokenizer(data, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length)"
   ],
   "id": "60c5c3cfaf792526",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T19:39:02.941607Z",
     "start_time": "2024-12-09T19:39:02.936848Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def data_collator(data):\n",
    "    input_ids = torch.stack([f[0] for f in data])\n",
    "    attention_mask = torch.stack([f[1] for f in data])\n",
    "\n",
    "    labels = input_ids.clone()\n",
    "    labels[input_ids == tokenizer.pad_token_id] = -100\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels\n",
    "    }"
   ],
   "id": "efea00349a680a41",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T19:39:04.597328Z",
     "start_time": "2024-12-09T19:39:04.594391Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "# Function to check for english text\n",
    "def is_english(text):\n",
    "  pattern = r'^[A-Za-z0-9\\s.,!?\\'\":;()&*%#$@^_+-=<>{}[\\]\\\\/|]*$'\n",
    "  return bool(re.match(pattern, text))"
   ],
   "id": "e7bdaac3696c9d4f",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T19:54:33.210120Z",
     "start_time": "2024-12-09T19:54:33.206610Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_train_eval_data(tokenized_data, test_size=0.2, random_state=42):\n",
    "    # Tokenize the data\n",
    "    input_ids = tokenized_data[\"input_ids\"]\n",
    "    attention_mask = tokenized_data[\"attention_mask\"]\n",
    "    \n",
    "    # Split the data\n",
    "    train_input_ids, eval_input_ids, train_attention_mask, eval_attention_mask = train_test_split(\n",
    "        input_ids, attention_mask, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # Create the TensorDataset objects\n",
    "    train_dataset = TensorDataset(train_input_ids, train_attention_mask)\n",
    "    eval_dataset = TensorDataset(eval_input_ids, eval_attention_mask)\n",
    "    \n",
    "    return train_dataset, eval_dataset"
   ],
   "id": "70c6e1a4724cc076",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T19:39:08.077006Z",
     "start_time": "2024-12-09T19:39:08.073543Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def save_model_and_tokenizer(model, tokenizer, local_path=\"./trained-model\"):\n",
    "    print(f\"\\n[+] saving model & tokenizer to: {local_path}\")\n",
    "    model.save_pretrained(local_path)\n",
    "    tokenizer.save_pretrained(local_path)"
   ],
   "id": "73ee33f908ef0c55",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "id": "ab2cb84b38d163ba",
    "ExecuteTime": {
     "end_time": "2024-12-09T19:39:09.834194Z",
     "start_time": "2024-12-09T19:39:09.829539Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_training_arguments(learning_rate=5e-5, epochs=3):\n",
    "    # Define parameters for training\n",
    "    training_config = TrainingArguments(\n",
    "        output_dir=\"./fine-tuned-gpt2\",\n",
    "        overwrite_output_dir=True,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        eval_strategy=\"steps\",\n",
    "        save_steps=500,\n",
    "        num_train_epochs=epochs,\n",
    "        save_total_limit=epochs,\n",
    "        logging_dir=\"./logs\",\n",
    "        logging_steps=10,\n",
    "        warmup_steps=500,\n",
    "        weight_decay=0.01,\n",
    "        use_cpu=False,\n",
    "        eval_steps=100,\n",
    "        learning_rate=learning_rate,\n",
    "    )\n",
    "    \n",
    "    return training_config"
   ],
   "id": "ab2cb84b38d163ba",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "id": "b4214f6e7b859601",
    "ExecuteTime": {
     "end_time": "2024-12-09T19:54:51.744114Z",
     "start_time": "2024-12-09T19:54:51.740421Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model(model, train_data, eval_data, tokenizer, training_args):\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_data,\n",
    "        eval_dataset=eval_data,\n",
    "        data_collator=data_collator,\n",
    "    )\n",
    "    \n",
    "    # Start training\n",
    "    trainer.train()\n",
    "    \n",
    "    # Save model after training\n",
    "    save_model_and_tokenizer(model, tokenizer)"
   ],
   "id": "b4214f6e7b859601",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T19:40:47.570516Z",
     "start_time": "2024-12-09T19:39:16.199565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model, tokenizer = load_model_and_tokenizer()\n",
    "dialog_data = preprocess_south_park_dialog_data(tokenizer)\n",
    "\n",
    "tokenized_data = tokenize_data(dialog_data, tokenizer)\n",
    "\n",
    "train_data, eval_data = get_train_eval_data(tokenized_data)\n",
    "\n",
    "train_model(model, train_data, eval_data, tokenizer, get_training_arguments())\n"
   ],
   "id": "68f76cbc7c4414fc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] loading model from Hugging-Face hub\n",
      "\n",
      "[+] Visualizing pre-processed south park dataset.\n",
      "['<USER>: You guys, you guys! Chef is going away. \\n <|endoftext|>\\n<BOT>: Going away? For how long?\\n<|endoftext|>\\n', \"<USER>: Forever.\\n <|endoftext|>\\n<BOT>: I'm sorry boys.\\n<|endoftext|>\\n\"]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='5319' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  12/5319 01:05 < 9:36:47, 0.15 it/s, Epoch 0.01/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[31], line 5\u001B[0m\n\u001B[0;32m      2\u001B[0m dialog_data \u001B[38;5;241m=\u001B[39m preprocess_south_park_dialog_data(tokenizer)\n\u001B[0;32m      4\u001B[0m train_data, eval_data \u001B[38;5;241m=\u001B[39m get_train_eval_data(dialog_data)\n\u001B[1;32m----> 5\u001B[0m train_model(model, train_data, eval_data, tokenizer)\n",
      "Cell \u001B[1;32mIn[30], line 11\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m(model, train_data, eval_data, tokenizer)\u001B[0m\n\u001B[0;32m      2\u001B[0m trainer \u001B[38;5;241m=\u001B[39m Trainer(\n\u001B[0;32m      3\u001B[0m     model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[0;32m      4\u001B[0m     args\u001B[38;5;241m=\u001B[39mget_training_arguments(),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m      7\u001B[0m     data_collator\u001B[38;5;241m=\u001B[39mdata_collator,\n\u001B[0;32m      8\u001B[0m )\n\u001B[0;32m     10\u001B[0m \u001B[38;5;66;03m# Start training\u001B[39;00m\n\u001B[1;32m---> 11\u001B[0m trainer\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m# Save model after training\u001B[39;00m\n\u001B[0;32m     14\u001B[0m save_model_and_tokenizer(model, tokenizer)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\trainer.py:2164\u001B[0m, in \u001B[0;36mTrainer.train\u001B[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[0;32m   2162\u001B[0m         hf_hub_utils\u001B[38;5;241m.\u001B[39menable_progress_bars()\n\u001B[0;32m   2163\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 2164\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m inner_training_loop(\n\u001B[0;32m   2165\u001B[0m         args\u001B[38;5;241m=\u001B[39margs,\n\u001B[0;32m   2166\u001B[0m         resume_from_checkpoint\u001B[38;5;241m=\u001B[39mresume_from_checkpoint,\n\u001B[0;32m   2167\u001B[0m         trial\u001B[38;5;241m=\u001B[39mtrial,\n\u001B[0;32m   2168\u001B[0m         ignore_keys_for_eval\u001B[38;5;241m=\u001B[39mignore_keys_for_eval,\n\u001B[0;32m   2169\u001B[0m     )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\trainer.py:2527\u001B[0m, in \u001B[0;36mTrainer._inner_training_loop\u001B[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[0;32m   2521\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m context():\n\u001B[0;32m   2522\u001B[0m     tr_loss_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining_step(model, inputs, num_items_in_batch)\n\u001B[0;32m   2524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   2525\u001B[0m     args\u001B[38;5;241m.\u001B[39mlogging_nan_inf_filter\n\u001B[0;32m   2526\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_torch_xla_available()\n\u001B[1;32m-> 2527\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (torch\u001B[38;5;241m.\u001B[39misnan(tr_loss_step) \u001B[38;5;129;01mor\u001B[39;00m torch\u001B[38;5;241m.\u001B[39misinf(tr_loss_step))\n\u001B[0;32m   2528\u001B[0m ):\n\u001B[0;32m   2529\u001B[0m     \u001B[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001B[39;00m\n\u001B[0;32m   2530\u001B[0m     tr_loss \u001B[38;5;241m=\u001B[39m tr_loss \u001B[38;5;241m+\u001B[39m tr_loss \u001B[38;5;241m/\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mglobal_step \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_globalstep_last_logged)\n\u001B[0;32m   2531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Training on New Dataset\n",
    "Fine-tuning on new dialog dataset - \"casual_data_windows.csv\" from reddit conversations."
   ],
   "id": "41fedbf9f75c2983"
  },
  {
   "cell_type": "code",
   "source": [
    "# Load model and tokenizer\n",
    "model, tokenizer = load_model_and_tokenizer(local_path=\"./models/trained-model-2.6-loss\")"
   ],
   "metadata": {
    "id": "ivYIjl05SP6-",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1733703669212,
     "user_tz": 300,
     "elapsed": 333,
     "user": {
      "displayName": "Takis Panel",
      "userId": "10823998020771479779"
     }
    },
    "ExecuteTime": {
     "end_time": "2024-12-09T19:43:39.960342Z",
     "start_time": "2024-12-09T19:43:39.331554Z"
    }
   },
   "id": "ivYIjl05SP6-",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] loading model from local directory.\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "id": "5968c86d9ce9a4ee",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1733703550815,
     "user_tz": 300,
     "elapsed": 22163,
     "user": {
      "displayName": "Takis Panel",
      "userId": "10823998020771479779"
     }
    },
    "ExecuteTime": {
     "end_time": "2024-12-09T19:43:58.991261Z",
     "start_time": "2024-12-09T19:43:51.537907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Pre-process new dataset: \"casual_data_windows.csv\"\n",
    "df = pd.read_csv(\"./data/casual_data_windows.csv\")\n",
    "\n",
    "# Drop unused column\n",
    "df = df.drop(columns=[\"2\"])\n",
    "\n",
    "# Remove rows where C2 and C3 share data\n",
    "df = df[df[\"0\"] != df[\"1\"]]\n",
    "\n",
    "# Remove duplicates in columns\n",
    "df = df.drop_duplicates(subset=[\"0\", \"1\"])\n",
    "\n",
    "# Drop rows with any empty cells\n",
    "df = df.dropna()\n",
    "df = df[df.apply(lambda row: row.str.strip().all(), axis=1)]\n"
   ],
   "id": "5968c86d9ce9a4ee",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "951c32237024587f",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1733703554485,
     "user_tz": 300,
     "elapsed": 224,
     "user": {
      "displayName": "Takis Panel",
      "userId": "10823998020771479779"
     }
    },
    "outputId": "b95ee32e-7e23-42e7-8e7e-bd9df1bf646a",
    "ExecuteTime": {
     "end_time": "2024-12-09T19:44:18.872644Z",
     "start_time": "2024-12-09T19:44:18.863668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#  Visualize dataset\n",
    "df.head()"
   ],
   "id": "951c32237024587f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Unnamed: 0                                                  0  \\\n",
       "0           0            What kind of phone(s) do you guys have?   \n",
       "1           1  I have a pixel. It's pretty great. Much better...   \n",
       "2           2       Does it really charge all the way in 15 min?   \n",
       "3           3            What kind of phone(s) do you guys have?   \n",
       "4           4  Samsung Galaxy J1. It's my first cell phone an...   \n",
       "\n",
       "                                                   1  \n",
       "0  I have a pixel. It's pretty great. Much better...  \n",
       "1       Does it really charge all the way in 15 min?  \n",
       "2  Pretty fast. I've never timed it, but it's und...  \n",
       "3  Samsung Galaxy J1. It's my first cell phone an...  \n",
       "4  What do you think of it? Anything you don't like?  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>What kind of phone(s) do you guys have?</td>\n",
       "      <td>I have a pixel. It's pretty great. Much better...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I have a pixel. It's pretty great. Much better...</td>\n",
       "      <td>Does it really charge all the way in 15 min?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Does it really charge all the way in 15 min?</td>\n",
       "      <td>Pretty fast. I've never timed it, but it's und...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>What kind of phone(s) do you guys have?</td>\n",
       "      <td>Samsung Galaxy J1. It's my first cell phone an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Samsung Galaxy J1. It's my first cell phone an...</td>\n",
       "      <td>What do you think of it? Anything you don't like?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7b80d21b507d05c7",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1733703562943,
     "user_tz": 300,
     "elapsed": 6568,
     "user": {
      "displayName": "Takis Panel",
      "userId": "10823998020771479779"
     }
    },
    "outputId": "a84af7f0-ea5f-4d11-c32a-560e59a19e53",
    "ExecuteTime": {
     "end_time": "2024-12-09T19:46:50.951124Z",
     "start_time": "2024-12-09T19:46:48.169526Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Format data for training\n",
    "dialog_data = []\n",
    "illegal_line_count = 0\n",
    "for _, row in df.iterrows():\n",
    "    user = row[\"0\"]\n",
    "    bot = row[\"1\"]\n",
    "\n",
    "    if is_english(user) and is_english(bot):\n",
    "        dialog_data.append(f\"<USER>: {user} {tokenizer.eos_token}. <BOT>: {bot}{tokenizer.eos_token}.\")\n",
    "    else:\n",
    "        illegal_line_count += 1\n",
    "        \n",
    "print(f\"[-] Removed {illegal_line_count} lines.\")"
   ],
   "id": "7b80d21b507d05c7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-] Removed 7896 lines.\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1090618a800c6ede",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1733703676992,
     "user_tz": 300,
     "elapsed": 134,
     "user": {
      "displayName": "Takis Panel",
      "userId": "10823998020771479779"
     }
    },
    "outputId": "c6674e51-047f-47f9-cd27-1b073d9b4e8e",
    "ExecuteTime": {
     "end_time": "2024-12-09T19:47:46.042080Z",
     "start_time": "2024-12-09T19:47:46.038657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(dialog_data[:3])\n",
    "print(f\"\\n[+] total data samples: {len(dialog_data)}\")"
   ],
   "id": "1090618a800c6ede",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"<USER>: What kind of phone(s) do you guys have? <|endoftext|>. <BOT>: I have a pixel. It's pretty great. Much better than what I had before. <|endoftext|>.\", \"<USER>: I have a pixel. It's pretty great. Much better than what I had before.  <|endoftext|>. <BOT>: Does it really charge all the way in 15 min?<|endoftext|>.\", \"<USER>: Does it really charge all the way in 15 min? <|endoftext|>. <BOT>: Pretty fast. I've never timed it, but it's under half an hour. <|endoftext|>.\"]\n",
      "\n",
      "[+] total data samples: 41682\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T19:54:01.095143Z",
     "start_time": "2024-12-09T19:53:48.835690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Tokenize the data\n",
    "tokenized_data = tokenize_data(dialog_data, tokenizer)\n",
    "print(tokenized_data)"
   ],
   "id": "96eb379c47261336",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[   27, 29904, 31175,  ..., 50256, 50256, 50256],\n",
      "        [   27, 29904, 31175,  ..., 50256, 50256, 50256],\n",
      "        [   27, 29904, 31175,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [   27, 29904, 31175,  ..., 50256, 50256, 50256],\n",
      "        [   27, 29904, 31175,  ..., 50256, 50256, 50256],\n",
      "        [   27, 29904, 31175,  ..., 50256, 50256, 50256]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T19:54:42.767479Z",
     "start_time": "2024-12-09T19:54:42.746988Z"
    }
   },
   "cell_type": "code",
   "source": "train_data, eval_data = get_train_eval_data(tokenized_data)",
   "id": "37dcf8db3176c95b",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "id": "bb5597c280afa5a2",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1733703787997,
     "user_tz": 300,
     "elapsed": 20021,
     "user": {
      "displayName": "Takis Panel",
      "userId": "10823998020771479779"
     }
    },
    "ExecuteTime": {
     "end_time": "2024-12-09T19:55:36.176010Z",
     "start_time": "2024-12-09T19:54:55.709607Z"
    }
   },
   "cell_type": "code",
   "source": "train_model(model, train_data, eval_data, tokenizer, get_training_arguments(epochs=5))",
   "id": "bb5597c280afa5a2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73' max='10425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   73/10425 00:37 < 1:30:34, 1.90 it/s, Epoch 0.03/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[52], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m train_model(model, train_data, eval_data, tokenizer, get_training_arguments(epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m))\n",
      "Cell \u001B[1;32mIn[51], line 11\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m(model, train_data, eval_data, tokenizer, training_args)\u001B[0m\n\u001B[0;32m      2\u001B[0m trainer \u001B[38;5;241m=\u001B[39m Trainer(\n\u001B[0;32m      3\u001B[0m     model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[0;32m      4\u001B[0m     args\u001B[38;5;241m=\u001B[39mtraining_args,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m      7\u001B[0m     data_collator\u001B[38;5;241m=\u001B[39mdata_collator,\n\u001B[0;32m      8\u001B[0m )\n\u001B[0;32m     10\u001B[0m \u001B[38;5;66;03m# Start training\u001B[39;00m\n\u001B[1;32m---> 11\u001B[0m trainer\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m# Save model after training\u001B[39;00m\n\u001B[0;32m     14\u001B[0m save_model_and_tokenizer(model, tokenizer)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\trainer.py:2164\u001B[0m, in \u001B[0;36mTrainer.train\u001B[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[0;32m   2162\u001B[0m         hf_hub_utils\u001B[38;5;241m.\u001B[39menable_progress_bars()\n\u001B[0;32m   2163\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 2164\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m inner_training_loop(\n\u001B[0;32m   2165\u001B[0m         args\u001B[38;5;241m=\u001B[39margs,\n\u001B[0;32m   2166\u001B[0m         resume_from_checkpoint\u001B[38;5;241m=\u001B[39mresume_from_checkpoint,\n\u001B[0;32m   2167\u001B[0m         trial\u001B[38;5;241m=\u001B[39mtrial,\n\u001B[0;32m   2168\u001B[0m         ignore_keys_for_eval\u001B[38;5;241m=\u001B[39mignore_keys_for_eval,\n\u001B[0;32m   2169\u001B[0m     )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\trainer.py:2527\u001B[0m, in \u001B[0;36mTrainer._inner_training_loop\u001B[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[0;32m   2521\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m context():\n\u001B[0;32m   2522\u001B[0m     tr_loss_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining_step(model, inputs, num_items_in_batch)\n\u001B[0;32m   2524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   2525\u001B[0m     args\u001B[38;5;241m.\u001B[39mlogging_nan_inf_filter\n\u001B[0;32m   2526\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_torch_xla_available()\n\u001B[1;32m-> 2527\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (torch\u001B[38;5;241m.\u001B[39misnan(tr_loss_step) \u001B[38;5;129;01mor\u001B[39;00m torch\u001B[38;5;241m.\u001B[39misinf(tr_loss_step))\n\u001B[0;32m   2528\u001B[0m ):\n\u001B[0;32m   2529\u001B[0m     \u001B[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001B[39;00m\n\u001B[0;32m   2530\u001B[0m     tr_loss \u001B[38;5;241m=\u001B[39m tr_loss \u001B[38;5;241m+\u001B[39m tr_loss \u001B[38;5;241m/\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mglobal_step \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_globalstep_last_logged)\n\u001B[0;32m   2531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 52
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
